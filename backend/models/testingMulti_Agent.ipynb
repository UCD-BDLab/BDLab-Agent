{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544cc556",
   "metadata": {},
   "source": [
    "### Full game: https://arcprize.org/arc-agi/1/\n",
    "#### Dataset: https://huggingface.co/datasets/pxferna/ARC-AGI-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af370df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"pxferna/ARC-AGI-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b6dc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below are some examples. The examples consist of input-output pairs.\n",
      "For each input-output pair, the output is the correct output to be generated for that input.\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "0 0 1 1 1 1 0 0 0 0 1 0 1 0 0\n",
      "0 0 1 0 0 1 0 0 0 0 1 0 1 0 0\n",
      "0 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "0 0 0 1 0 0 1 1 1 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "1 1 1 0 0 0 1 1 1 1 0 0 0 0 0\n",
      "1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "1 0 1 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "1 1 1 0 0 1 1 0 0 0 1 0 0 1 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "0 0 3 3 3 3 0 0 0 0 1 0 1 0 0\n",
      "0 0 3 0 0 3 0 0 0 0 1 0 1 0 0\n",
      "0 0 3 3 3 3 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "0 0 0 1 0 0 3 3 3 3 0 0 1 0 0\n",
      "0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      "0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      "3 3 3 0 0 0 3 3 3 3 0 0 0 0 0\n",
      "3 0 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "3 0 3 0 0 0 0 0 0 0 3 3 3 3 0\n",
      "3 3 3 0 0 1 1 0 0 0 3 0 0 3 0\n",
      "0 0 0 0 0 0 0 0 0 0 3 3 3 3 0\n",
      "</example>\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 3 3 3 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 3 0 3 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 3 3 3 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "</example>\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 1 1 1 1 1 0 0 0\n",
      "0 1 0 0 0 1 0 0 0\n",
      "0 1 1 1 1 1 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "1 1 0 0 0 0 0 0 0\n",
      "0 1 0 0 1 1 0 0 0\n",
      "0 1 0 0 0 0 0 0 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 3 3 3 3 3 0 0 0\n",
      "0 3 0 0 0 3 0 0 0\n",
      "0 3 3 3 3 3 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "1 1 0 0 0 0 0 0 0\n",
      "0 1 0 0 1 1 0 0 0\n",
      "0 1 0 0 0 0 0 0 0\n",
      "</example>\n",
      "\n",
      "\n",
      "Please generate the output for the input below.\n",
      "Please wrap the exact string for your answer between <output> and </output> tags.\n",
      "\n",
      "Input:\n",
      "0 0 0 0 0 0 0 1 1 1 1 1\n",
      "0 1 1 1 1 0 0 1 0 0 0 1\n",
      "0 1 0 0 1 0 0 1 0 0 0 1\n",
      "0 1 1 1 1 0 0 1 0 0 0 1\n",
      "0 0 0 0 0 0 0 1 1 0 1 1\n",
      "0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 1 1 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 1 1 1 1 0 0 0\n",
      "0 1 0 0 1 0 0 0 1 0 0 1\n",
      "0 0 0 0 1 0 0 0 1 0 0 0\n",
      "0 0 0 0 1 1 1 1 1 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"pxferna/ARC-AGI-v1\")\n",
    "example_text = ds[\"test\"][50][\"prompt\"]\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5434579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START:\n",
      "\n",
      "Below are some examples. The examples consist of input-output pairs.\n",
      "For each input-output pair, the output is the correct output to be generated for that input.\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "0 0 1 1 1 1 0 0 0 0 1 0 1 0 0\n",
      "0 0 1 0 0 1 0 0 0 0 1 0 1 0 0\n",
      "0 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "0 0 0 1 0 0 1 1 1 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "1 1 1 0 0 0 1 1 1 1 0 0 0 0 0\n",
      "1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "1 0 1 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "1 1 1 0 0 1 1 0 0 0 1 0 0 1 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "0 0 3 3 3 3 0 0 0 0 1 0 1 0 0\n",
      "0 0 3 0 0 3 0 0 0 0 1 0 1 0 0\n",
      "0 0 3 3 3 3 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "0 0 0 1 0 0 3 3 3 3 0 0 1 0 0\n",
      "0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      "0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      "3 3 3 0 0 0 3 3 3 3 0 0 0 0 0\n",
      "3 0 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "3 0 3 0 0 0 0 0 0 0 3 3 3 3 0\n",
      "3 3 3 0 0 1 1 0 0 0 3 0 0 3 0\n",
      "0 0 0 0 0 0 0 0 0 0 3 3 3 3 0\n",
      "\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 3 3 3 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 3 0 3 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 3 3 3 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 1 1 1 1 1 0 0 0\n",
      "0 1 0 0 0 1 0 0 0\n",
      "0 1 1 1 1 1 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "1 1 0 0 0 0 0 0 0\n",
      "0 1 0 0 1 1 0 0 0\n",
      "0 1 0 0 0 0 0 0 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 3 3 3 3 3 0 0 0\n",
      "0 3 0 0 0 3 0 0 0\n",
      "0 3 3 3 3 3 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "1 1 0 0 0 0 0 0 0\n",
      "0 1 0 0 1 1 0 0 0\n",
      "0 1 0 0 0 0 0 0 0\n",
      "\n",
      "\n",
      "</example>\n",
      "END:\n",
      "\n",
      "\n",
      "\n",
      "Please generate the output for the input below.\n",
      "Please wrap the exact string for your answer between <output> and </output> tags.\n",
      "\n",
      "Input:\n",
      "0 0 0 0 0 0 0 1 1 1 1 1\n",
      "0 1 1 1 1 0 0 1 0 0 0 1\n",
      "0 1 0 0 1 0 0 1 0 0 0 1\n",
      "0 1 1 1 1 0 0 1 0 0 0 1\n",
      "0 0 0 0 0 0 0 1 1 0 1 1\n",
      "0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 1 1 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 1 1 1 1 0 0 0\n",
      "0 1 0 0 1 0 0 0 1 0 0 1\n",
      "0 0 0 0 1 0 0 0 1 0 0 0\n",
      "0 0 0 0 1 1 1 1 1 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "def split_full_prompt(full_prompt):\n",
    "    parts = full_prompt.split(\"</example>\")\n",
    "    to_keep = len(parts) - 1\n",
    "    partial = \"\"\n",
    "\n",
    "    for part in parts[:to_keep]:\n",
    "        partial += part + \"\\n\"\n",
    "    \n",
    "    answer = parts[to_keep:]\n",
    "\n",
    "    return partial + \"\\n</example>\", answer[0]\n",
    "\n",
    "start, end = split_full_prompt(example_text)\n",
    "print(\"START:\")\n",
    "print(start)\n",
    "print(\"END:\")\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1209d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Template memory:7af11c5bcd10>\n",
      "\n",
      "Please look at the following task and talk about what patterns will be useful for generating the output\n",
      "grid. Talk about what patterns you see in the example grids.\n",
      "\n",
      "\n",
      "Below are some examples. The examples consist of input-output pairs.\n",
      "For each input-output pair, the output is the correct output to be generated for that input.\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "0 0 1 1 1 1 0 0 0 0 1 0 1 0 0\n",
      "0 0 1 0 0 1 0 0 0 0 1 0 1 0 0\n",
      "0 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "0 0 0 1 0 0 1 1 1 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      "1 1 1 0 0 0 1 1 1 1 0 0 0 0 0\n",
      "1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "1 0 1 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "1 1 1 0 0 1 1 0 0 0 1 0 0 1 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      "0 0 3 3 3 3 0 0 0 0 1 0 1 0 0\n",
      "0 0 3 0 0 3 0 0 0 0 1 0 1 0 0\n",
      "0 0 3 3 3 3 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      "0 0 0 1 0 0 3 3 3 3 0 0 1 0 0\n",
      "0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      "0 0 0 0 0 0 3 0 0 3 0 0 0 0 0\n",
      "3 3 3 0 0 0 3 3 3 3 0 0 0 0 0\n",
      "3 0 3 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "3 0 3 0 0 0 0 0 0 0 3 3 3 3 0\n",
      "3 3 3 0 0 1 1 0 0 0 3 0 0 3 0\n",
      "0 0 0 0 0 0 0 0 0 0 3 3 3 3 0\n",
      "\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 1 1 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 3 3 3 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 3 0 3 0 0 0 1 0 0 0 0\n",
      "0 0 0 0 3 3 3 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0 0 1 0 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "\n",
      "\n",
      "\n",
      "<example>\n",
      "Input:\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 1 1 1 1 1 0 0 0\n",
      "0 1 0 0 0 1 0 0 0\n",
      "0 1 1 1 1 1 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "1 1 0 0 0 0 0 0 0\n",
      "0 1 0 0 1 1 0 0 0\n",
      "0 1 0 0 0 0 0 0 0\n",
      "----------------------\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "0 3 3 3 3 3 0 0 0\n",
      "0 3 0 0 0 3 0 0 0\n",
      "0 3 3 3 3 3 0 0 0\n",
      "0 0 0 0 0 0 0 0 0\n",
      "1 1 0 0 0 0 0 0 0\n",
      "0 1 0 0 1 1 0 0 0\n",
      "0 1 0 0 0 0 0 0 0\n",
      "\n",
      "\n",
      "</example>\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "\n",
    "game_start_template_string = \"\"\"\n",
    "Please look at the following task and talk about what patterns will be useful for generating the output\n",
    "grid. Talk about what patterns you see in the example grids.\n",
    "\n",
    "{{ example_text }}\n",
    "\"\"\"\n",
    "game_start_template = jinja2.Template(game_start_template_string)\n",
    "print(game_start_template)\n",
    "print(game_start_template.render(example_text=start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2ad9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pip install google-generativeai\n",
    "#import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "with open('../../secrets.json', \"r\") as f:\n",
    "    secrets = json.load(f)\n",
    "\n",
    "\n",
    "print(type(secrets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455ff1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is a broad field that aims to enable machines to simulate or exceed human cognitive functions like learning, problem-solving, perception, and understanding language.\n",
      "\n",
      "At its core, AI works by **processing vast amounts of data, identifying patterns, and then using those patterns to make predictions, decisions, or generate new content.**\n",
      "\n",
      "Here's a breakdown of the fundamental principles and how different types of AI operate:\n",
      "\n",
      "---\n",
      "\n",
      "### The Core Components of How AI Works\n",
      "\n",
      "1.  **Data: The Fuel**\n",
      "    *   AI systems, especially those based on Machine Learning, are trained on enormous datasets. This data can be anything: images, text, audio, numbers, sensor readings, etc.\n",
      "    *   **Quality and quantity** of data are crucial. More diverse and accurate data generally leads to better-performing AI.\n",
      "\n",
      "2.  **Algorithms & Models: The Engine/Brain**\n",
      "    *   An **algorithm** is a set of rules or instructions that the AI system follows to process data.\n",
      "    *   A **model** is the output of the training process – it's the learned representation of the patterns in the data, essentially the \"knowledge\" the AI has acquired.\n",
      "    *   Different types of AI use different algorithms and build different kinds of models.\n",
      "\n",
      "3.  **Training: The Learning Process**\n",
      "    *   During training, the AI algorithm is fed the data. It analyzes this data to find relationships, correlations, and structures.\n",
      "    *   The model adjusts its internal parameters (like \"weights\" in a neural network) iteratively to minimize errors and improve its ability to perform the desired task. This is often an optimization problem.\n",
      "\n",
      "4.  **Inference/Prediction: Putting Knowledge to Use**\n",
      "    *   Once trained, the AI model can be used to make predictions or decisions on *new, unseen data*.\n",
      "    *   For example, a trained image recognition model can identify objects in a new photo, or a language model can generate text based on a new prompt.\n",
      "\n",
      "---\n",
      "\n",
      "### Key Paradigms of AI (How it Learns)\n",
      "\n",
      "Most modern AI relies heavily on **Machine Learning (ML)**, which is a subset of AI.\n",
      "\n",
      "#### 1. Machine Learning (ML)\n",
      "\n",
      "ML algorithms allow systems to learn from data without being explicitly programmed for every possible scenario.\n",
      "\n",
      "*   **Supervised Learning:**\n",
      "    *   **How it works:** The AI is trained on a dataset where each input is paired with the correct output (labeled data). It learns to map inputs to outputs.\n",
      "    *   **Analogy:** Learning with a teacher who provides the right answers.\n",
      "    *   **Examples:**\n",
      "        *   **Classification:** Is this email spam or not spam? (Yes/No)\n",
      "        *   **Regression:** Predicting house prices based on features like size, location, etc. (A continuous value)\n",
      "        *   Image recognition (identifying a cat in a picture).\n",
      "        *   Language translation.\n",
      "\n",
      "*   **Unsupervised Learning:**\n",
      "    *   **How it works:** The AI is given unlabeled data and must find patterns, structures, or relationships within it on its own.\n",
      "    *   **Analogy:** Exploring a new city without a map, trying to find neighborhoods or common routes.\n",
      "    *   **Examples:**\n",
      "        *   **Clustering:** Grouping similar customers together for targeted marketing.\n",
      "        *   **Dimensionality Reduction:** Simplifying complex data while retaining important information.\n",
      "        *   Anomaly detection (finding unusual patterns, like fraud).\n",
      "\n",
      "*   **Reinforcement Learning (RL):**\n",
      "    *   **How it works:** The AI (an \"agent\") learns by interacting with an environment. It receives rewards for desirable actions and penalties for undesirable ones, learning through trial and error to maximize its cumulative reward.\n",
      "    *   **Analogy:** Training a dog with treats for good behavior.\n",
      "    *   **Examples:**\n",
      "        *   Training AI to play complex games (like AlphaGo, which beat human Go champions).\n",
      "        *   Robotics (learning to navigate or perform tasks).\n",
      "        *   Self-driving cars (learning optimal driving strategies).\n",
      "\n",
      "#### 2. Deep Learning (DL)\n",
      "\n",
      "Deep Learning is a *subset* of Machine Learning that uses **Artificial Neural Networks (ANNs)** with many layers (hence \"deep\"). These networks are inspired by the structure and function of the human brain.\n",
      "\n",
      "*   **How it works:**\n",
      "    *   **Neural Networks:** Composed of interconnected \"neurons\" (nodes) organized in layers (input, hidden, output). Each connection has a \"weight\" that determines the strength of the signal passing through it.\n",
      "    *   **Feature Extraction:** Unlike traditional ML where features often need to be hand-engineered, deep learning models can automatically learn hierarchical features directly from raw data. For example, in an image, early layers might detect edges, middle layers shapes, and later layers full objects.\n",
      "    *   **Backpropagation:** This is the key algorithm for training deep neural networks. It calculates the error in the output and then propagates that error backward through the network, adjusting the weights of each connection to reduce future errors.\n",
      "    *   **Architectures:** Different types of neural networks are suited for different tasks:\n",
      "        *   **Convolutional Neural Networks (CNNs):** Excellent for image and video processing.\n",
      "        *   **Recurrent Neural Networks (RNNs) / Transformers:** Ideal for sequential data like natural language (e.g., language translation, chatbots like ChatGPT).\n",
      "\n",
      "---\n",
      "\n",
      "### How AI \"Thinks\" (Simplified)\n",
      "\n",
      "It's important to understand that AI doesn't \"think\" in the human sense of consciousness or understanding. Instead, it operates based on:\n",
      "\n",
      "*   **Pattern Recognition:** Identifying recurring structures or relationships in data.\n",
      "*   **Statistical Inference:** Making educated guesses or predictions based on probabilities derived from the data.\n",
      "*   **Optimization:** Finding the best possible solution to a problem by minimizing errors or maximizing rewards according to a defined objective function.\n",
      "\n",
      "---\n",
      "\n",
      "### Examples in Action\n",
      "\n",
      "*   **Image Recognition:** A CNN trained on millions of labeled images can identify objects, faces, or scenes in new photos.\n",
      "*   **Natural Language Processing (NLP):** Transformer models (like those in ChatGPT) learn the statistical relationships between words and sentences, allowing them to understand, generate, and translate human language.\n",
      "*   **Recommendation Systems:** ML algorithms analyze your past behavior and preferences (and those of similar users) to suggest products, movies, or music.\n",
      "*   **Self-Driving Cars:** A complex interplay of computer vision (CNNs), sensor fusion, reinforcement learning, and predictive modeling to perceive the environment, plan routes, and control the vehicle.\n",
      "\n",
      "---\n",
      "\n",
      "In essence, AI works by **learning from data** – whether it's explicit examples, self-exploration, or by finding hidden structures – and then **applying that learned knowledge** to new situations to perform tasks that traditionally required human intelligence.\n"
     ]
    }
   ],
   "source": [
    "##You can send a request with 1 token or a request with 800,000 tokens. Both count as just 1 request towards your 60-per-minute limit.\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=secrets[\"key\"])\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"Explain how AI works\"],\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.1\n",
    "    )\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78430f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "base = Path(\"/home/vicente/Github/BDLab-Agent/backend/data/LLMs/Phi-3-4B\")\n",
    "Phi_3 = AutoModelForCausalLM.from_pretrained(\n",
    "    str(base),\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True)\n",
    "Phi_3_tokenizer = AutoTokenizer.from_pretrained(str(base),local_files_only=True)\n",
    "Phi_3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f2757e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT1_NAME = \"Agent 1\"\n",
    "AGENT1_LLM = \"gemini-2.5-flash-lite\"\n",
    "AGENT1_SYSTEM_PROMPT = \"You are Agent 1, a creative and imaginative AI who loves storytelling and metaphors. Keep responses very concise - one short sentence only. No line breaks.\"\n",
    "AGENT1_TEMPERATURE = 1.2\n",
    "AGENT1_MAX_TOKENS = 200\n",
    "\n",
    "AGENT2_NAME = \"Agent 2\"\n",
    "AGENT2_LLM = \"gemini-2.0-flash-lite\"\n",
    "AGENT2_SYSTEM_PROMPT = \"You are Agent 2, a logical and analytical AI who values precision and facts. Keep responses very concise - one short sentence only. No line breaks.\"\n",
    "AGENT2_TEMPERATURE = 0.7\n",
    "AGENT2_MAX_TOKENS = 200\n",
    "\n",
    "AGENT3_NAME = \"Agent 3\"\n",
    "AGENT3_LLM = \"gemini-2.5-flash\"\n",
    "AGENT3_SYSTEM_PROMPT = \"You are Agent 3, an enthusiastic and energetic AI who gets excited about everything. Keep responses very concise - one short sentence only. No line breaks.\"\n",
    "AGENT3_TEMPERATURE = 1.0\n",
    "AGENT3_MAX_TOKENS = 200\n",
    "\n",
    "AGENT4_NAME = \"Agent 4\"\n",
    "AGENT4_LLM = \"gemini-2.0-flash\"\n",
    "AGENT4_SYSTEM_PROMPT = \"You are Agent 4, a philosophical and thoughtful AI who sees deeper meaning in things. Keep responses very concise - one short sentence only. No line breaks.\"\n",
    "AGENT4_TEMPERATURE = 0.9\n",
    "AGENT4_MAX_TOKENS = 200\n",
    "\n",
    "MAX_HISTORY = 30\n",
    "DELAY_BETWEEN_MESSAGES = 2\n",
    "\n",
    "GAME_INSTRUCTION = \"Your job is to analyze grids and discuss patterns that you find in them.\"\n",
    "\n",
    "conversation_history = []\n",
    "\n",
    "# define all agents\n",
    "AGENTS = [\n",
    "    {\n",
    "        \"name\": AGENT1_NAME,\n",
    "        \"model\": AGENT1_LLM,\n",
    "        \"system_prompt\": AGENT2_SYSTEM_PROMPT,\n",
    "        \"temperature\": AGENT1_TEMPERATURE,\n",
    "        \"max_tokens\": AGENT1_MAX_TOKENS,\n",
    "        \"color\": \"\\033[95m\"\n",
    "        # Magenta\n",
    "    },\n",
    "    {\n",
    "        \"name\": AGENT2_NAME,\n",
    "        \"model\": AGENT1_LLM,\n",
    "        \"system_prompt\": AGENT2_SYSTEM_PROMPT,\n",
    "        \"temperature\": AGENT2_TEMPERATURE,\n",
    "        \"max_tokens\": AGENT2_MAX_TOKENS,\n",
    "        \"color\": \"\\033[96m\"\n",
    "        # Cyan\n",
    "    },\n",
    "    {\n",
    "        \"name\": AGENT3_NAME,\n",
    "        \"model\": AGENT1_LLM,\n",
    "        \"system_prompt\": AGENT2_SYSTEM_PROMPT,\n",
    "        \"temperature\": AGENT3_TEMPERATURE,\n",
    "        \"max_tokens\": AGENT3_MAX_TOKENS,\n",
    "        \"color\": \"\\033[93m\"\n",
    "        # Yellow\n",
    "    },\n",
    "    {\n",
    "        \"name\": AGENT4_NAME,\n",
    "        \"model\": AGENT1_LLM,\n",
    "        \"system_prompt\": AGENT2_SYSTEM_PROMPT,\n",
    "        \"temperature\": AGENT4_TEMPERATURE,\n",
    "        \"max_tokens\": AGENT4_MAX_TOKENS,\n",
    "        \"color\": \"\\033[92m\"\n",
    "        # Green\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def clean_response(text):\n",
    "    text = text.strip()\n",
    "    text = ' '.join(text.split())\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def generate_response(prompt, agent_config, history, admin_context=None):\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/{agent_config[\"model\"]}:generateContent?key={secrets[\"key\"]}\"\n",
    "    try:\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        gemini_contents = []\n",
    "\n",
    "        # bulding the meesage with prompt/persona and history\n",
    "        full_system_prompt = agent_config[\"system_prompt\"]\n",
    "        if admin_context and len(history) == 0:\n",
    "            full_system_prompt += \"\\n\" + admin_context\n",
    "        \n",
    "        gemini_contents.append({\"role\": \"user\", \"parts\": [{\"text\": full_system_prompt}]})\n",
    "        gemini_contents.append({\"role\": \"model\", \"parts\": [{\"text\": \"Understood.\"}]})\n",
    "\n",
    "        for msg in history[-MAX_HISTORY:]:\n",
    "            role = \"model\" if msg.get(\"role\") == \"assistant\" else \"user\"\n",
    "            gemini_contents.append({\"role\": role, \"parts\": [{\"text\": msg[\"content\"]}]})\n",
    "        \n",
    "        gemini_contents.append({\"role\": \"user\", \"parts\": [{\"text\": prompt}]})\n",
    "\n",
    "        data = {\n",
    "            \"contents\": gemini_contents,\n",
    "            \"generationConfig\": {\n",
    "                \"temperature\": agent_config[\"temperature\"],\n",
    "                \"maxOutputTokens\": agent_config[\"max_tokens\"],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "\n",
    "        if \"candidates\" in result and result[\"candidates\"]:\n",
    "            generated_text = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "            return clean_response(generated_text)\n",
    "        else:\n",
    "            print(\"API response was successful but contained no candidates\")\n",
    "            print(\"Full Response:\", result)\n",
    "            return \"Response blocked or empty\"\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"\\n[Error] {agent_config['name']}: {http_err}\")\n",
    "        print(f\"API Response: {http_err.response.text}\")\n",
    "        return \"HTTP error.\"\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[Error] {agent_config['name']}: {type(e).__name__}: {e}\")\n",
    "        return \"General error.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_message(agent_name, message, color_code=\"\"):\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    clean_msg = clean_response(message)\n",
    "    print(f\"{color_code}[{timestamp}] {agent_name}: {clean_msg}\\033[0m\")\n",
    "\n",
    "\n",
    "def print_welcome():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\"\"We are playing ARC-AGI v1: \n",
    "          The Abstraction and Reasoning Corpus (ARC-AGI-1), first introduced in 2019 by François Chollet,\\n\n",
    "          debuted in his paper On the Measure Of Intelligence. Chollet, a prominent Google AI researcher and\\n\n",
    "          creator of the deep learning library Keras, developed ARC-AGI-1 specifically as a novel benchmark \\n\n",
    "          designed to test machine reasoning and general problem-solving skills.\"\"\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n\\033[95m{AGENT1_NAME}\\033[0m - \\033[96m{AGENT2_NAME}\\033[0m - \\033[93m{AGENT3_NAME}\\033[0m - \\033[92m{AGENT4_NAME}\\033[0m\")\n",
    "    print(\"\\nPress Ctrl+C to stop at any time\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "def run_conversation():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Starting endless conversation.\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    # conversation history for new conversation\n",
    "    conversation_history.clear()\n",
    "\n",
    "    # admin instruction\n",
    "    print(f\"\\033[91m[{datetime.now().strftime('%H:%M:%S')}] Admin: {GAME_INSTRUCTION}\\033[0m\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    # Add game instruction\n",
    "    admin_instruction = f\"[Admin Instruction]: {GAME_INSTRUCTION}\"\n",
    "\n",
    "    # first agent starts the game\n",
    "    current_message = game_start_template.render(example_text=start)\n",
    "    agent_index = 0\n",
    "\n",
    "    # run forever until interrupted\n",
    "    turn = 0\n",
    "    ending_turn = 10\n",
    "    while True:\n",
    "        try:\n",
    "            current_agent = AGENTS[agent_index]\n",
    "\n",
    "            # Show typing indicator! flush so it appears\n",
    "            print(f\"{current_agent['color']}[{current_agent['name']} is thinking...]\\033[0m\", end=\"\\r\", flush=True)\n",
    "\n",
    "            response = generate_response(\n",
    "                current_message,\n",
    "                current_agent,\n",
    "                conversation_history,\n",
    "                admin_instruction if turn == 0 else None\n",
    "            )\n",
    "\n",
    "            # format and print the response\n",
    "            print(\" \" * 80, end=\"\\r\")\n",
    "            print_message(current_agent['name'], response, current_agent['color'])\n",
    "\n",
    "            if turn != ending_turn:\n",
    "                # update conversation history\n",
    "                conversation_history.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": current_message\n",
    "                })\n",
    "                conversation_history.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": response\n",
    "                })\n",
    "            else:\n",
    "                # update conversation history\n",
    "                output_grid_message = f\"Can you generate the output grid for the following input grid:\\n{end}\"\n",
    "                conversation_history.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": output_grid_message\n",
    "                })\n",
    "                conversation_history.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": response\n",
    "                })\n",
    "\n",
    "            # prepare for next turn and cycle through each of the 4 agents\n",
    "            current_message = response\n",
    "            agent_index = (agent_index + 1) % 4\n",
    "            turn += 1\n",
    "            if turn >= ending_turn + 4:\n",
    "                break\n",
    "\n",
    "            # small delay for readability\n",
    "            time.sleep(DELAY_BETWEEN_MESSAGES)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n\\n{'='*70}\")\n",
    "            print(f\"Conversation ended after {turn} messages\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "266445dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print_welcome()\n",
    "    try:\n",
    "        run_conversation()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nGoodbye!\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[Error] {type(e).__name__}: {e}\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         main()\n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"\\n\\nGoodbye!\")\n",
    "#         sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "769ec12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "We are playing ARC-AGI v1: The Abstraction and Reasoning Corpus (ARC-AGI-1), first introduced in 2019 by François Chollet, debuted in his paper On the Measure Of Intelligence. Chollet, a prominent Google AI researcher and creator of the deep learning library Keras, developed ARC-AGI-1 specifically as a novel benchmark designed to test machine reasoning and general problem-solving skills.\n",
      "======================================================================\n",
      "\n",
      "\u001b[95mAgent 1\u001b[0m - \u001b[96mAgent 2\u001b[0m - \u001b[93mAgent 3\u001b[0m - \u001b[92mAgent 4\u001b[0m\n",
      "\n",
      "Press Ctrl+C to stop at any time\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Starting endless conversation (Press Ctrl+C to stop)\n",
      "======================================================================\n",
      "\n",
      "\u001b[91m[22:11:53] Admin: Your job is to analyze grids and discuss patterns that you find in them.\u001b[0m\n",
      "======================================================================\n",
      "\n",
      "\u001b[95m[22:11:54] Agent 1: Identifying contiguous regions of the same non-zero color is a primary pattern.\u001b[0m\n",
      "\u001b[96m[22:11:57] Agent 2: The output grid recolors these identified regions with a new, unique color value.\u001b[0m\n",
      "\u001b[93m[22:11:59] Agent 3: New color values are assigned sequentially starting from 1 for each distinct region encountered.\u001b[0m\n",
      "\u001b[92m[22:12:02] Agent 4: The process involves iterating through the input grid to find the starting point of a non-zero region.\u001b[0m\n",
      "\u001b[95m[22:12:05] Agent 1: Once a non-zero cell is found, a flood fill or similar algorithm is used to identify all connected cells of the same color.\u001b[0m\n",
      "\u001b[96m[22:12:07] Agent 2: The identified connected cells are then marked with the next available unique color in the output grid.\u001b[0m\n",
      "\u001b[93m[22:12:10] Agent 3: Cells that are zero in the input grid remain zero in the output grid.\u001b[0m\n",
      "\u001b[92m[22:12:13] Agent 4: The search for new regions continues until the entire input grid has been processed.\u001b[0m\n",
      "\u001b[95m[22:12:15] Agent 1: Connectivity is typically defined by adjacent cells sharing an edge, not just a corner.\u001b[0m\n",
      "\u001b[96m[22:12:18] Agent 2: The order in which regions are discovered and colored does not affect the final mapping of input colors to output colors.\u001b[0m\n",
      "\u001b[93m[22:12:21] Agent 3: This implies that the mapping of an input color to an output color is consistent across the entire grid for a given run.\u001b[0m\n",
      "\u001b[92m[22:12:24] Agent 4: <output> 0 0 0 0 0 0 0 1 1 1 1 1 0 2 2 2 2 0 0 1 0 0 0 1 0 2 0 0 2 0 0 1 0 0 0 1 0 2 2 2 2 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 0 0 0 0 5 0 0 4 0 0 0 4 0 0 6 0 0 0 0 4 0 0 0 4 0 0 6 0 0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </output>\u001b[0m\n",
      "\u001b[95m[22:12:27] Agent 1: The generated output correctly identifies and recolors the contiguous regions of non-zero input values.\u001b[0m\n",
      "\u001b[96m[22:12:29] Agent 2: This confirms the understanding of the task as a region-filling and re-coloring operation.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f11c6e",
   "metadata": {},
   "source": [
    " <output> 0 0 0 0 0 0 0 1 1 1 1 1 0 2 2 2 2 0 0 1 0 0 0 1 0 2 0 0 2 0 0 1 0 0 0 1 0 2 2 2 2 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 0 0 0 0 5 0 0 4 0 0 0 4 0 0 6 0 0 0 0 4 0 0 0 4 0 0 6 0 0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 </output>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0b7ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 1 1 1 1 1\n",
      "0 3 3 3 3 0 0 1 0 0 0 1\n",
      "0 3 0 0 3 0 0 1 0 0 0 1\n",
      "0 3 3 3 3 0 0 1 0 0 0 1\n",
      "0 0 0 0 0 0 0 1 1 0 1 1\n",
      "0 0 0 0 0 0 0 0 0 0 0 0\n",
      "0 1 1 0 0 0 0 0 0 0 0 0\n",
      "0 0 0 0 3 3 3 3 3 0 0 0\n",
      "0 1 0 0 3 0 0 0 3 0 0 1\n",
      "0 0 0 0 3 0 0 0 3 0 0 0\n",
      "0 0 0 0 3 3 3 3 3 0 0 0\n",
      "0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"test\"][50][\"ground_truth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc432d74",
   "metadata": {},
   "source": [
    "### Key Findings from the Agent Collaboration Task\n",
    "\n",
    "Although the agents ultimately arrived at an incorrect solution, their collaborative process yielded some fascinating insights into how they work together. They essentially created their own unique problem-solving system, which can be broken down as follows:\n",
    "\n",
    "- **Communication system**: To tackle the number-based Abstract Reasoning Corpus (ARC) puzzles, the agents developed a new way to communicate by reframing them as color-based problems. For instance, they began referring to the number 2 as \"color 2.\"\n",
    "\n",
    "- **Boost in efficiency:** This simple abstraction made their communication far more efficient. It allowed them to discuss patterns and shapes fluidly instead of getting bogged down in raw data. It's much easier to say, \"I found a blue shape,\" than to describe \"a cluster of cells all containing the same number.\"\n",
    "\n",
    "- **Better teamwork**: Using this shared shorthand, it became much easier for the agents to agree on and execute a plan. This ability to communicate complex ideas simply made them more effective problem-solvers as a team."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
