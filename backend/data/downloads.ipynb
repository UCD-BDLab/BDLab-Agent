{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdde583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramos\\Desktop\\GitHub\\BDLab-Agent\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gemma 2 9B IT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramos\\Desktop\\GitHub\\BDLab-Agent\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n",
      "Fetching 12 files: 100%|██████████| 12/12 [03:49<00:00, 19.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma 2b IT download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "# visit https://huggingface.co/google/gemma-2-9b-it to accept the terms.\n",
    "print(\"Downloading Gemma 2 9B IT...\")\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"google/gemma2b-it\",\n",
    "    local_dir=\"LLMs/Gemma2b-it\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "print(\"Gemma 2b IT download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f153259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gemma 2b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [02:39<00:00, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma 2b download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading Gemma 2b...\")\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"google/gemma2-9b\",\n",
    "    local_dir=\"LLMs/Gemma2-9b\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "print(\"Gemma 2b download complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92813c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gemma 2b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 19 files: 100%|██████████| 19/19 [01:01<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma 2b download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading Phi-3-mini...\")\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    local_dir=\"LLMs/Phi3-mini\",\n",
    "    local_dir_use_symlinks=False,\n",
    ")\n",
    "\n",
    "print(\"Phi-3-mini download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a225c84",
   "metadata": {},
   "source": [
    "## Link\n",
    "\n",
    "- Hugging face page: https://huggingface.co/sentence-transformers\n",
    "- Website: https://sbert.net/\n",
    "- Models: https://sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "- Image-Text: https://huggingface.co/sentence-transformers/clip-ViT-L-14\n",
    "- Image & Text model CLIP, which maps text and images to a shared vector space. For applications of the models, have a look in our documentation SBERT.net - Image Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca0f0a",
   "metadata": {},
   "source": [
    "## Sentence Transformers\n",
    "\n",
    "Characteristics of Sentence Transformer (a.k.a bi-encoder) models:\n",
    "\n",
    "- Calculates a fixed-size vector representation (embedding) given texts or images.\n",
    "- Embedding calculation is often efficient, embedding similarity calculation is very fast.\n",
    "- Applicable for a wide range of tasks, such as semantic textual similarity, semantic search, clustering, classification, paraphrase mining, and more.\n",
    "- Often used as a first step in a two-step retrieval process, where a Cross-Encoder (a.k.a. reranker) model is used to re-rank the top-k results from the bi-encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7809ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "# calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05031583",
   "metadata": {},
   "source": [
    "| Weight Class | Model Name                              | Dimensions | Description                                                                 |\n",
    "|--------------|------------------------------------------|------------|-----------------------------------------------------------------------------|\n",
    "| Lightweight  | all-MiniLM-L6-v2                         | 384        | Speed. The most downloaded model. Best for high-volume, real-time apps. |\n",
    "| Lightweight  | all-MiniLM-L12-v2                        | 384        | Best Value. Adds 6 more layers than L6 for better accuracy with minimal latency penalty. |\n",
    "| Midweight    | all-distilroberta-v1                    | 768        | Fast Semantic. A distilled version of RoBERTa; faster than MPNet but better than MiniLM. |\n",
    "| Midweight    | all-mpnet-base-v2                       | 768        | Accuracy. The highest-performing general-purpose model in this repo. |\n",
    "| Heavyweight  | clip-ViT-L-14                           | 768        | Multimodal Heavy. Handles both images and text. High memory usage compared to text-only. |\n",
    "| Heavyweight  | paraphrase-multilingual-mpnet-base-v2   | 768        | Global Reach. Supports 50+ languages. Computationally heavy due to the large vocabulary. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bb50f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramos\\Desktop\\GitHub\\BDLab-Agent\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ramos\\Desktop\\GitHub\\BDLab-Agent\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Downloading MiniLM-L6 (sentence-transformers/all-MiniLM-L6-v2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:42<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Downloading MPNet-Base (sentence-transformers/all-mpnet-base-v2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 28 files: 100%|██████████| 28/28 [02:29<00:00,  5.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Downloading Multilingual-MPNet (sentence-transformers/paraphrase-multilingual-mpnet-base-v2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 27 files: 100%|██████████| 27/27 [06:48<00:00, 15.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Downloading CLIP-L14 (sentence-transformers/clip-ViT-L-14) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 13 files: 100%|██████████| 13/13 [01:39<00:00,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete. Models are stored in the './embeddings/' folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_models = {\n",
    "    # Lightweight (fast)\n",
    "    \"MiniLM-L6\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \n",
    "    # Midweight (balanced)\n",
    "    \"MPNet-Base\": \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \n",
    "    # Heavyweight (multilingual)\n",
    "    \"Multilingual-MPNet\": \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    \n",
    "    # Multimodal (image + text)\n",
    "    \"CLIP-L14\": \"sentence-transformers/clip-ViT-L-14\"\n",
    "}\n",
    "\n",
    "for name, repo_id in embedding_models.items():\n",
    "    print(f\"Downloading {name} ({repo_id}):\")\n",
    "    snapshot_download(\n",
    "        repo_id=repo_id,\n",
    "        local_dir=f\"./Embeddings/{name}\",\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "\n",
    "print(\"Models are stored in the './Embeddings/' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e28d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightweight Embedding Shape: (2, 384)\n",
      "Lightweight Similarity Score: [[0.05952562019228935], [0.6251088380813599]]\n",
      "Midweight Similarity Score: 0.6149\n",
      "Cross-lingual Similarity: 0.8960\n",
      "CLIP Text-Image Scores: tensor([[0.2773, 0.1695]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from sentence_transformers import util\n",
    "\n",
    "base_path = \"./Embeddings\"\n",
    "\n",
    "model_light = SentenceTransformer(os.path.join(base_path, \"MiniLM-L6\"), device=\"cuda\")\n",
    "sentences = [\"The cat sits outside\", \"A man is playing guitar\"]\n",
    "embeddings = model_light.encode(sentences)\n",
    "\n",
    "score_light = util.cos_sim(embeddings, model_light.encode([\"A person playing an instrument\"]))\n",
    "print(f\"Lightweight Embedding Shape: {embeddings.shape}\")\n",
    "print(f\"Lightweight Similarity Score: {score_light.tolist()}\") \n",
    "\n",
    "model_mid = SentenceTransformer(os.path.join(base_path, \"MPNet-Base\"), device=\"cuda\")\n",
    "query = \"A person playing an instrument\"\n",
    "query_emb = model_mid.encode(query)\n",
    "\n",
    "score = util.cos_sim(query_emb, model_mid.encode([\"A man is playing guitar\"]))\n",
    "print(f\"Midweight Similarity Score: {score.item():.4f}\")\n",
    "\n",
    "model_multi = SentenceTransformer(os.path.join(base_path, \"Multilingual-MPNet\"), device=\"cuda\")\n",
    "es_text = \"El gato está afuera\"\n",
    "en_text = \"The cat sits outside\"\n",
    "\n",
    "sim = util.cos_sim(model_multi.encode(es_text), model_multi.encode(en_text))\n",
    "print(f\"Cross-lingual Similarity: {sim.item():.4f}\")\n",
    "\n",
    "model_clip = SentenceTransformer(os.path.join(base_path, \"CLIP-L14\"), device=\"cuda\")\n",
    "img = Image.open('two_dogs_in_snow.jpg') \n",
    "img_emb = model_clip.encode(img)\n",
    "text_emb = model_clip.encode([\"dogs playing in winter\", \"a sunny beach\"])\n",
    "\n",
    "clip_scores = util.cos_sim(img_emb, text_emb)\n",
    "print(f\"CLIP Text-Image Scores: {clip_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad725d8f",
   "metadata": {},
   "source": [
    "## INSTRUCTOR models\n",
    "\n",
    "Some INSTRUCTOR models, such as hkunlp/instructor-large, are natively supported in Sentence Transformers. These models are special, as they are trained with instructions in mind. Notably, the primary difference between normal Sentence Transformer models and Instructor models is that the latter do not include the instructions themselves in the pooling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"hkunlp/instructor-large\")\n",
    "embeddings = model.encode(\n",
    "    [\n",
    "        \"Dynamical Scalar Degree of Freedom in Horava-Lifshitz Gravity\",\n",
    "        \"Comparison of Atmospheric Neutrino Flux Calculations at Low Energies\",\n",
    "        \"Fermion Bags in the Massive Gross-Neveu Model\",\n",
    "        \"QCD corrections to Associated t-tbar-H production at the Tevatron\",\n",
    "    ],\n",
    "    prompt=\"Represent the Medicine sentence for clustering: \",\n",
    ")\n",
    "print(embeddings.shape)\n",
    "# => (4, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"hkunlp/instructor-large\")\n",
    "\n",
    "query = \"where is the food stored in a yam plant\"\n",
    "query_instruction = (\n",
    "    \"Represent the Wikipedia question for retrieving supporting documents: \"\n",
    ")\n",
    "\n",
    "corpus = [\n",
    "    'Yams are perennial herbaceous vines native to Africa, Asia, and the Americas and cultivated for the consumption of their starchy tubers in many temperate and tropical regions. The tubers themselves, also called \"yams\", come in a variety of forms owing to numerous cultivars and related species.',\n",
    "    \"The disparate impact theory is especially controversial under the Fair Housing Act because the Act regulates many activities relating to housing, insurance, and mortgage loansâ€”and some scholars have argued that the theory's use under the Fair Housing Act, combined with extensions of the Community Reinvestment Act, contributed to rise of sub-prime lending and the crash of the U.S. housing market and ensuing global economic recession\",\n",
    "    \"Disparate impact in United States labor law refers to practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another, even though rules applied by employers or landlords are formally neutral. Although the protected classes vary by statute, most federal civil rights laws protect based on race, color, religion, national origin, and sex as protected traits, and some laws include disability status and other traits as well.\",\n",
    "]\n",
    "corpus_instruction = \"Represent the Wikipedia document for retrieval: \"\n",
    "\n",
    "query_embedding = model.encode(query, prompt=query_instruction)\n",
    "corpus_embeddings = model.encode(corpus, prompt=corpus_instruction)\n",
    "similarities = util.cos_sim(query_embedding, corpus_embeddings)\n",
    "print(similarities)\n",
    "\n",
    "# => tensor([[0.8835, 0.7037, 0.6970]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284429ef",
   "metadata": {},
   "source": [
    "## Cross Encoders:\n",
    "\n",
    "### Usage\n",
    "\n",
    "### Characteristics of Cross Encoder (a.k.a reranker) models:\n",
    "\n",
    "- Calculates a similarity score given pairs of texts.\n",
    "\n",
    "- Generally provides superior performance compared to a Sentence Transformer (a.k.a. bi-encoder) model.\n",
    "\n",
    "- Often slower than a Sentence Transformer model, as it requires computation for each pair rather than each text.\n",
    "\n",
    "- Due to the previous 2 characteristics, Cross Encoders are often used to re-rank the top-k results from a Sentence Transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 1. Load a pre-trained CrossEncoder model\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Predict scores for a pair of sentences\n",
    "scores = model.predict([\n",
    "    (\"How many people live in Berlin?\", \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\"),\n",
    "    (\"How many people live in Berlin?\", \"Berlin is well known for its museums.\"),\n",
    "])\n",
    "# => array([ 8.607138 , -4.3200774], dtype=float32)\n",
    "\n",
    "# 3. Rank a list of passages for a query\n",
    "query = \"How many people live in Berlin?\"\n",
    "passages = [\n",
    "    \"Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\",\n",
    "    \"Berlin is well known for its museums.\",\n",
    "    \"In 2014, the city state Berlin had 37,368 live births (+6.6%), a record number since 1991.\",\n",
    "    \"The urban area of Berlin comprised about 4.1 million people in 2014, making it the seventh most populous urban area in the European Union.\",\n",
    "    \"The city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019\",\n",
    "    \"An estimated 300,000-420,000 Muslims reside in Berlin, making up about 8-11 percent of the population.\",\n",
    "    \"Berlin is subdivided into 12 boroughs or districts (Bezirke).\",\n",
    "    \"In 2015, the total labour force in Berlin was 1.85 million.\",\n",
    "    \"In 2013 around 600,000 Berliners were registered in one of the more than 2,300 sport and fitness clubs.\",\n",
    "    \"Berlin has a yearly total of about 135 million day visitors, which puts it in third place among the most-visited city destinations in the European Union.\",\n",
    "]\n",
    "ranks = model.rank(query, passages)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Query:\", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{passages[rank['corpus_id']]}\")\n",
    "\"\"\"\n",
    "Query: How many people live in Berlin?\n",
    "8.92    The urban area of Berlin comprised about 4.1 million people in 2014, making it the seventh most populous urban area in the European Union.\n",
    "8.61    Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.\n",
    "8.24    An estimated 300,000-420,000 Muslims reside in Berlin, making up about 8-11 percent of the population.\n",
    "7.60    In 2014, the city state Berlin had 37,368 live births (+6.6%), a record number since 1991.\n",
    "6.35    In 2013 around 600,000 Berliners were registered in one of the more than 2,300 sport and fitness clubs.\n",
    "5.42    Berlin has a yearly total of about 135 million day visitors, which puts it in third place among the most-visited city destinations in the European Union.\n",
    "3.45    In 2015, the total labour force in Berlin was 1.85 million.\n",
    "0.33    Berlin is subdivided into 12 boroughs or districts (Bezirke).\n",
    "-4.24   The city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019\n",
    "-4.32   Berlin is well known for its museums.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffa3a8",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
