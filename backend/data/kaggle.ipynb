{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d200781b",
   "metadata": {},
   "source": [
    "Getting datasets from kaggle API\n",
    "first we will need to install the kaggle API: https://www.kaggle.com/docs/api#authentication\n",
    "\n",
    "what i had to do \n",
    "```bash\n",
    "mkdir -p ~/.config/kaggle\n",
    "cp /home/vicente/Github/BDLab-Agent/kaggle.json ~/.config/kaggle/kaggle.json\n",
    "chmod 600 ~/.config/kaggle/kaggle.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle import KaggleApi\n",
    "import os\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "datasets = [\n",
    "    \"nickfecondo/united-states-presidential-executive-orders\",\n",
    "    \"davidgauthier/central-bank-speeches\",\n",
    "    \"drlexus/fed-statements-and-minutes\",\n",
    "    \"ankurzing/sentiment-analysis-in-commodity-market-gold\",\n",
    "    \"mohamedgreshamahdi/fakenewsnet\",\n",
    "    \"bittlingmayer/amazonreviews\",\n",
    "]\n",
    "\n",
    "for data in datasets:\n",
    "    owner, name = data.split('/')\n",
    "    dest = f'./kaggle/{name}'\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    api.dataset_download_files(\n",
    "        dataset=data,\n",
    "        path=dest,\n",
    "        unzip=True\n",
    "    )\n",
    "    print(f\"{data} downloaded into {dest}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbf030",
   "metadata": {},
   "source": [
    "# Kaggle Datasets Overview\n",
    "\n",
    "This document summarises the seven text‑heavy datasets you downloaded from Kaggle, highlighting what each one contains and the columns or fields you will see in the raw files.\n",
    "\n",
    "## 1. Amazon Reviews  \n",
    "**Slug:** `bittlingmayer/amazonreviews` :contentReference[oaicite:0]{index=0}  \n",
    "\n",
    "| file(s) | format | what’s inside | main fields / structure |\n",
    "|---------|--------|---------------|-------------------------|\n",
    "| `train.ft.txt.bz2`<br>`test.ft.txt.bz2` | fastText‑style, one line per sample, compressed with *bz2* | ~3.6 M training reviews and 0.4 M test reviews for sentiment modelling | `__label__X $text` &nbsp;→ label (`1–5` star rating) and *review text* |\n",
    "\n",
    "Typical use‑case → quick sentiment‑analysis benchmarking with fastText or any text‑classification model.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Central Bank Speeches  \n",
    "**Slug:** `davidgauthier/central-bank-speeches` :contentReference[oaicite:1]{index=1}  \n",
    "\n",
    "| file | format | time span | key columns* |\n",
    "|------|--------|-----------|--------------|\n",
    "| `all_speeches.csv` | CSV (~151 MB) | 1997 – 2022 | `date`, `speaker`, `institution` (central bank), `country`, `title`, `speech` (full text), `url`, `language` |\n",
    "\n",
    "*Column list taken from the dataset card & common notebook usage; names may differ slightly in the actual file.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. FakeNewsNet  \n",
    "**Slug:** `mohamedgreshamahdi/fakenewsnet` :contentReference[oaicite:2]{index=2}  \n",
    "\n",
    "| folder / file | split | columns (per CSV) |\n",
    "|---------------|-------|-------------------|\n",
    "| `BuzzFeed_fake_news_content.csv`<br>`BuzzFeed_real_news_content.csv` | BuzzFeed | `id`, `url`, `title`, `text`, `publish_date`, `author`, `label` |\n",
    "| `GossipCop_*` | GossipCop | same layout |\n",
    "| `PolitiFact_*` | PolitiFact | same layout + fact‑checker metadata |\n",
    "\n",
    "Provides parallel *fake* vs *real* news stories ready for stance or deception detection tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Fed Statements & Minutes  \n",
    "**Slug:** `drlexus/fed-statements-and-minutes` :contentReference[oaicite:3]{index=3}  \n",
    "\n",
    "| file | rows | columns (common) |\n",
    "|------|------|-----------------|\n",
    "| `Fed_Scrape‑2015‑2023.csv` | >900 docs | `date`, `doc_type` (Statement / Minutes), `meeting`, `title`, `url`, `text` |\n",
    "\n",
    "Great for policy‑tone analysis, hawkish‑vs‑dovish classification, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Gold‑Commodity News Sentiment  \n",
    "**Slug:** `ankurzing/sentiment-analysis-in-commodity-market-gold` :contentReference[oaicite:4]{index=4}  \n",
    "\n",
    "| file | format | key columns |\n",
    "|------|--------|------------|\n",
    "| `gold-dataset-sinha-khandait.csv` | CSV | `timestamp`, `headline`, `price_sentiment` (Positive ∣ Neutral ∣ Negative ∣ None) |\n",
    "\n",
    "A lightweight headline‑only corpus for training/evaluating commodity‑price sentiment models.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. U.S. Presidential Executive Orders  \n",
    "**Slug:** `nickfecondo/united-states-presidential-executive-orders` :contentReference[oaicite:5]{index=5}  \n",
    "\n",
    "| file | size | main columns |\n",
    "|------|------|-------------|\n",
    "| `presidential_executive_orders.csv` | ~460 kB | `president`, `eo_number`, `date_signed`, `title`, `topic_tags`, `text`, `link` |\n",
    "\n",
    "Covers executive‑order texts from Clinton through Biden, useful for policy‑trend mining or historical NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. U.S. Senate Bill – Authorship Attribution  \n",
    "**Slug:** `markjma/authorship-attribution-on-a-us-senate-bill` :contentReference[oaicite:6]{index=6}  \n",
    "\n",
    "| folder | contents | note |\n",
    "|--------|----------|------|\n",
    "| `us-senate-bill/` | ~20 plain‑text files such as “*Taiwan Policy Act of 2022 – Final Draft.txt*” | Each file is the full bill text; there is **no** tabular metadata. File names encode the bill title / version. |\n",
    "\n",
    "Designed for stylometry or drafting‑stage authorship‑detection experiments.\n",
    "\n",
    "---\n",
    "\n",
    "### Footnotes  \n",
    "* Column names marked with * may vary slightly; they’re drawn from the public dataset cards or popular Kaggle notebooks.  \n",
    "* All datasets are UTF‑8 encoded unless noted otherwise.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
